<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI Governance &amp; Risk Frameworks – International Institute of AI Governance</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content="Conceptual, future-oriented overview of AI governance and risk frameworks. Provides a neutral orientation on how principles, governance processes and implementation practices can be structured through the 2020s and 2030s. Does not constitute legal advice, regulation or a formal standard."
  />

  <!-- Bootstrap 5 CSS -->
  <link
    href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
    rel="stylesheet"
  />

  <!-- Bootstrap Icons -->
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css"
  />

  <!-- Shared Theme -->
  <link rel="stylesheet" href="../styles.css" />
</head>
<body>
  <!-- Dynamic Navbar -->
  <div id="navbar-container"></div>

  <main>
    <!-- HERO: AI GOVERNANCE & RISK FRAMEWORKS (CONCEPTUAL, FUTURE-ORIENTED) -->
    <section class="hero-section hero-section--inner">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-lg-7">
            <div class="hero-kicker">
              <i class="bi bi-diagram-3" aria-hidden="true"></i>
              Standards · AI Governance &amp; Risk Frameworks (Conceptual Orientation)
            </div>
            <h1 class="hero-title">
              Orienting around <span class="highlight">AI governance &amp; risk frameworks</span> for the 2030s
            </h1>
            <p class="hero-subtitle">
              This page provides a neutral, future-oriented view of how AI governance and risk frameworks are
              commonly structured – from principles and governance processes to implementation practices and
              evidence. It does not create or replace any law, regulation, standard or supervisory guidance, and
              should not be treated as legal, risk or technical advice.
            </p>
          </div>
          <div class="col-lg-5 mt-4 mt-lg-0">
            <div class="hero-panel">
              <div class="hero-panel-title">
                How to interpret this page
              </div>
              <ul class="list-unstyled mb-3 small text-secondary">
                <li class="mb-2 d-flex align-items-start gap-2">
                  <i class="bi bi-info-circle" aria-hidden="true"></i>
                  <span>
                    Offers a conceptual “map” of AI governance and risk frameworks that organizations and institutions
                    may need to navigate through the 2020s and 2030s.
                  </span>
                </li>
                <li class="mb-2 d-flex align-items-start gap-2">
                  <i class="bi bi-x-circle" aria-hidden="true"></i>
                  <span>
                    Does <strong>not</strong> claim that IIAIG is a regulator, accreditation body, supervisory authority
                    or creator of binding technical standards in any jurisdiction.
                  </span>
                </li>
                <li class="mb-2 d-flex align-items-start gap-2">
                  <i class="bi bi-balance-scale" aria-hidden="true"></i>
                  <span>
                    Encourages alignment with relevant laws, regulations, standards and guidance, which remain the
                    responsibility of institutions and their professional advisers.
                  </span>
                </li>
              </ul>
              <a href="#landscape" class="btn btn-outline-light btn-sm me-2">
                Framework landscape
              </a>
              <a href="#model" class="btn btn-hero-primary btn-sm text-white">
                Conceptual AI governance model
              </a>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- SECTION: WHY FRAMEWORKS MATTER -->
    <section class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Overview</div>
            <h2 class="section-heading">Why AI governance &amp; risk frameworks matter</h2>
            <p class="section-subtitle">
              AI governance is not only a technical topic – it is about how organizations, universities and public
              institutions define responsibilities, make decisions, manage risk and demonstrate accountability over
              time. Frameworks provide the structure that connects these pieces in a repeatable, evidence-based way.
            </p>
          </div>
        </div>

        <div class="row g-4">
          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-columns-gap" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Connecting principles to practice</h5>
                <p class="card-text text-muted small mb-0">
                  Frameworks help translate high-level principles such as fairness, transparency and accountability
                  into concrete governance processes, controls and behaviors that can be implemented, monitored and
                  improved in practice, across the AI lifecycle and across disciplines.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-diagram-2" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Aligning diverse stakeholders</h5>
                <p class="card-text text-muted small mb-0">
                  A shared framework gives technical teams, legal, risk, ethics, business leaders, educators and
                  external partners a common vocabulary for discussing AI risks and responsibilities, reducing
                  fragmentation and ambiguity within and between institutions.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-clipboard-data" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Supporting assurance &amp; oversight</h5>
                <p class="card-text text-muted small mb-0">
                  Frameworks make it easier for boards, councils, auditors, regulators, funders and accreditation
                  bodies to understand how AI risks are identified, controlled and reported within an organization
                  or ecosystem – and how this will evolve as AI regulation matures.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mt-4 mb-0">
          Organizations typically work with a combination of regulatory requirements, sectoral guidelines,
          professional standards and internal policies when designing their AI governance frameworks today – and
          can expect this ecosystem to become more structured and data-driven through the 2030s.
        </p>
      </div>
    </section>

    <!-- SECTION: LANDSCAPE OF FRAMEWORKS -->
    <section id="landscape" class="section-padding strip-section">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Landscape</div>
            <h2 class="section-heading">Conceptual landscape of AI governance &amp; risk frameworks</h2>
            <p class="section-subtitle">
              The AI governance “landscape” usually contains several layers: binding rules, non-binding guidance,
              sectoral expectations and internal frameworks. The table below provides a neutral, high-level map of
              these layers. It does not attempt to list all specific laws or standards and should be adapted to local
              contexts.
            </p>
          </div>
        </div>

        <div class="table-responsive shadow-sm rounded-3">
          <table class="table table-bordered align-middle small mb-0">
            <thead class="table-light">
              <tr>
                <th scope="col">Layer (conceptual)</th>
                <th scope="col">Typical sources</th>
                <th scope="col">Illustrative focus</th>
                <th scope="col">Implication for AI governance</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th scope="row" class="fw-semibold">1. Legal &amp; regulatory</th>
                <td>
                  Laws, regulations, supervisory guidance and official rulings relevant to AI, data, privacy,
                  non-discrimination, consumer protection, fundamental rights and sector-specific oversight.
                </td>
                <td>
                  Binding obligations, prohibitions, reporting duties and enforcement powers that organizations
                  must respect when designing, procuring and using AI systems.
                </td>
                <td>
                  Defines minimum requirements and hard boundaries. AI governance frameworks must ensure
                  compliance with applicable legal regimes in all relevant jurisdictions, and update as those
                  regimes evolve.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">2. Standards &amp; professional guidelines</th>
                <td>
                  National and international standards bodies, professional associations, industry codes of
                  practice and ethical guidelines.
                </td>
                <td>
                  Recommended practices, terminology, technical and process patterns, and ethical commitments
                  that go beyond minimum legal requirements, often converging over time into de facto norms.
                </td>
                <td>
                  Provides reference points for how responsible AI governance can be implemented and assessed
                  in a more structured, comparable way, and how organizations may demonstrate maturity.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">3. Organizational governance frameworks</th>
                <td>
                  Internal policies, risk management frameworks, control catalogs, committee charters and codes
                  of conduct adopted by organizations, universities and public bodies.
                </td>
                <td>
                  Defines who is responsible for what, how decisions are escalated, and how AI risks are
                  integrated into enterprise risk, compliance and ethics structures.
                </td>
                <td>
                  Operationalizes external expectations within the specific context, culture, risk appetite and
                  mission of the organization – including education, research and public service mandates.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">4. Methodologies, tooling &amp; evidence</th>
                <td>
                  Internal methods, checklists, impact assessments, testing protocols, documentation practices
                  and technical tools used by teams building or assessing AI systems.
                </td>
                <td>
                  How AI lifecycle activities (design, data, training, deployment, monitoring, retirement) are
                  performed and documented in practice, and how evidence is captured for internal and external
                  stakeholders.
                </td>
                <td>
                  Provides the day-to-day mechanisms through which high-level governance commitments are put
                  into action and can be independently reviewed, audited or assured.
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <p class="small text-muted mt-4 mb-0">
          Organizations typically need to understand each of these layers and how they interact when building or
          improving their AI governance arrangements, especially as future regulation, standards and assurance
          practices become more harmonized across borders.
        </p>
      </div>
    </section>

    <!-- SECTION: THREE-LAYER CONCEPTUAL MODEL -->
    <section id="model" class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Conceptual Model</div>
            <h2 class="section-heading">A three-layer view of AI governance &amp; risk management</h2>
            <p class="section-subtitle">
              Many organizations find it useful to think about AI governance and risk management in three
              interconnected layers: principles, governance processes and implementation practices. The cards below
              present this view in neutral, non-prescriptive terms that can evolve with future regulation and
              standards.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-4">
            <div class="card pathway-card h-100">
              <div class="card-body">
                <div class="pathway-pill">
                  <i class="bi bi-motherboard" aria-hidden="true"></i>
                  Layer 1 – Principles &amp; objectives
                </div>
                <p class="small text-muted mb-0">
                  Organizations articulate the values, principles and overall objectives that should govern their use
                  of AI – for example, commitments around safety, human oversight, fairness, explainability,
                  accountability and respect for rights – aligned with legal, ethical and societal expectations and
                  periodically revisited as AI capabilities change.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card pathway-card h-100">
              <div class="card-body">
                <div class="pathway-pill">
                  <i class="bi bi-building-gear" aria-hidden="true"></i>
                  Layer 2 – Governance structures &amp; processes
                </div>
                <p class="small text-muted mb-0">
                  Principles are embedded into committees, roles, policies and processes: who can approve AI use
                  cases, how risks are assessed and prioritized, how issues are escalated, and how accountability to
                  internal and external stakeholders is maintained over the life of each AI system or service.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card pathway-card h-100">
              <div class="card-body">
                <div class="pathway-pill">
                  <i class="bi bi-gear-wide-connected" aria-hidden="true"></i>
                  Layer 3 – Implementation, monitoring &amp; evidence
                </div>
                <p class="small text-muted mb-0">
                  Teams apply concrete methods and controls across the AI lifecycle: data governance, model
                  evaluation, documentation, monitoring, incident management and retirement – generating evidence
                  that frameworks are working in practice, and enabling independent review and continuous
                  improvement.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          Effective AI governance includes feedback loops between these layers: experience from implementation
          informs process improvements, which in turn may lead to refined principles or objectives, especially as
          regulations, standards and stakeholder expectations evolve over the next decade.
        </p>
      </div>
    </section>

    <!-- SECTION: FUTURE TRENDS IN AI GOVERNANCE FRAMEWORKS -->
    <section class="section-padding strip-section">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Future-Ready View</div>
            <h2 class="section-heading">How AI governance frameworks may evolve through the 2030s</h2>
            <p class="section-subtitle">
              While future developments will depend on policymakers and standard-setters, organizations can anticipate
              several broad trends in AI governance and risk frameworks. The cards below present a neutral,
              forward-looking view that does not predict or announce any specific regulation or standard.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-diagram-3" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Greater convergence &amp; comparability</h5>
                <p class="text-muted small mb-0">
                  Over time, AI governance expectations may converge into more consistent reference points for risk
                  classes, documentation, testing and oversight – making it easier to compare AI risk management
                  approaches across organizations, sectors and jurisdictions, while still respecting local law.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-bar-chart-line" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">More data-driven assurance</h5>
                <p class="text-muted small mb-0">
                  Frameworks may increasingly rely on structured metrics, indicators and testing evidence – for
                  example, around robustness, performance, governance process adherence or incident trends – while
                  recognizing the limits of metrics and the need for qualitative judgment and context.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-people-fill" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Broader stakeholder involvement</h5>
                <p class="text-muted small mb-0">
                  AI governance frameworks are likely to place greater emphasis on diverse stakeholder input,
                  including affected communities, users, students and staff – not only specialists – when designing,
                  evaluating and revising AI systems and the policies that govern them.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          These trends are indicative, not guaranteed. Organizations should monitor developments in their sectors and
          jurisdictions and adapt their frameworks through formal governance processes.
        </p>
      </div>
    </section>

    <!-- SECTION: ROLE OF A PROFESSIONAL INSTITUTE -->
    <section class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Roles &amp; Boundaries</div>
            <h2 class="section-heading">Conceptual role of a professional AI governance institute</h2>
            <p class="section-subtitle">
              The table below contrasts areas that typically belong to regulators and standard-setters with areas
              where a professional institute focused on AI governance may contribute in a complementary, non-regulatory
              way. This is a general orientation, not a description of any specific arrangement or recognition.
            </p>
          </div>
        </div>

        <div class="table-responsive shadow-sm rounded-3">
          <table class="table table-bordered align-middle small mb-0">
            <thead class="table-light">
              <tr>
                <th scope="col">Area</th>
                <th scope="col">Regulators / standard-setters</th>
                <th scope="col">Professional AI governance institute (conceptual)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th scope="row" class="fw-semibold">Legal &amp; regulatory obligations</th>
                <td>
                  Create, interpret and enforce laws, regulations and binding supervisory guidance. Define
                  sanctions and formal compliance expectations.
                </td>
                <td>
                  Does <strong>not</strong> create or enforce law. May help professionals interpret how AI
                  governance concepts relate to existing regulatory themes, always deferring to official sources
                  and qualified legal advice.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">Technical &amp; process standards</th>
                <td>
                  Develop formal standards and reference documents through recognized standardization processes,
                  where applicable.
                </td>
                <td>
                  May map how AI governance practices align with existing standards and emerging norms, providing
                  education and orientation without claiming to replace official standards or accreditation schemes.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">Professional competence</th>
                <td>
                  In some sectors, define licensing or mandatory registration schemes, where provided for by law.
                </td>
                <td>
                  May define curricula, examinations and continuing professional development expectations for AI
                  governance professionals, as a voluntary professional framework, complementing (not substituting)
                  sector-specific licensing or regulation where it exists.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">Ethics &amp; conduct expectations</th>
                <td>
                  Issue codes of conduct and sector-specific ethical rules where they are anchored in law or
                  regulation.
                </td>
                <td>
                  May publish a professional code of ethics and good practice for AI governance roles, which
                  members or certificants agree to follow, in addition to applicable legal and institutional
                  requirements.
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <p class="small text-muted mt-4 mb-0">
          Any individual or organization engaging with a professional institute remains responsible for understanding
          and complying with the applicable legal and regulatory requirements in their jurisdiction, including
          AI-specific rules and sectoral obligations.
        </p>
      </div>
    </section>

    <!-- SECTION: RISK VIEW & LINES OF DEFENCE (CONCEPTUAL) -->
    <section class="section-padding strip-section">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Risk View</div>
            <h2 class="section-heading">Viewing AI risk through a “three lines” governance lens</h2>
            <p class="section-subtitle">
              Many organizations adapt the familiar “three lines” governance model when integrating AI into their risk
              management. The cards below present a conceptual mapping that can be tailored to local context and
              regulatory expectations.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-1-circle" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">First line – AI owners &amp; builders</h5>
                <p class="card-text text-muted small mb-0">
                  Product teams, data scientists, engineers, educators and business owners who design, deploy and
                  operate AI-enabled processes are responsible for managing AI risks in day-to-day decisions, following
                  approved policies, controls and AI usage guidelines, and documenting key decisions.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-2-circle" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Second line – Risk, compliance &amp; governance</h5>
                <p class="card-text text-muted small mb-0">
                  Risk, compliance, legal, ethics and specialized AI governance functions provide frameworks,
                  oversight and challenge to ensure AI risks are identified, assessed and managed in line with the
                  organization’s risk appetite, AI policy and regulatory obligations, and that emerging expectations
                  are monitored over time.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-3-circle" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Third line – Internal &amp; external assurance</h5>
                <p class="card-text text-muted small mb-0">
                  Internal audit, independent reviewers and, where applicable, external auditors or assessors provide
                  assurance on whether AI governance frameworks are designed and operating effectively, reporting their
                  findings to senior management, boards and relevant oversight bodies.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          The exact allocation of responsibilities across these “lines” will vary by organization and sector; the model
          above is a neutral reference that can be adapted to specific governance structures and regulatory contexts.
        </p>
      </div>
    </section>

    <!-- SECTION: CLARITY – WHAT THIS PAGE DOES / DOES NOT DO -->
    <section class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Clarity</div>
            <h2 class="section-heading">What this AI Governance &amp; Risk Frameworks page does – and does not – represent</h2>
            <p class="section-subtitle">
              To keep expectations clear, it is important to distinguish conceptual orientation from legal, regulatory
              or technical standards.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-6">
            <div class="card why-card h-100 border-success-subtle">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-check2-circle" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">What this page does</h5>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    Provides a high-level, future-oriented conceptual overview of AI governance and risk frameworks
                    and how different layers interact.
                  </li>
                  <li class="mb-1">
                    Offers neutral vocabulary that organizations, universities and professionals can use in internal
                    discussions and planning.
                  </li>
                  <li class="mb-1">
                    Emphasizes the distinction between legal/regulatory obligations and voluntary professional or
                    organizational frameworks and practices.
                  </li>
                </ul>
              </div>
            </div>
          </div>

          <div class="col-md-6">
            <div class="card why-card h-100 border-danger-subtle">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-x-octagon" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">What this page does not do</h5>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    Does <strong>not</strong> introduce a new legal or regulatory framework and does not replace any
                    existing law, regulation or technical standard.
                  </li>
                  <li class="mb-1">
                    Does <strong>not</strong> claim that IIAIG is a regulator, accreditation body, supervisory
                    authority or standard-setter.
                  </li>
                  <li class="mb-1">
                    Does <strong>not</strong> serve as legal, risk or technical advice, or as an exhaustive catalog of
                    applicable obligations.
                  </li>
                  <li class="mb-1">
                    Does <strong>not</strong> create legal, financial or supervisory obligations for any institution
                    or individual.
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          Organizations should consult their own legal, compliance and risk advisors when interpreting and applying
          AI-related laws, regulations and standards in their specific context, and when designing or revising their
          AI governance frameworks.
        </p>
      </div>
    </section>

    <!-- SECTION: NEXT STEPS -->
    <section class="section-padding strip-section">
      <div class="container text-center">
        <div class="row justify-content-center mb-4">
          <div class="col-lg-8">
            <div class="section-kicker">Next Steps</div>
            <h2 class="section-heading">Using this orientation in your AI governance journey</h2>
            <p class="section-subtitle">
              Boards, executives, risk and compliance teams, universities and practitioners can use this page as a
              starting point to map their own AI governance and risk frameworks against relevant legal, regulatory and
              professional expectations – and to plan for more structured, evidence-based AI governance through the
              2030s.
            </p>
          </div>
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-center gap-3 mb-3">
          <a href="/standards/esg.html" class="btn btn-outline-secondary">
            ESG &amp; AI governance orientation
          </a>
          <a href="/standards/ethics-panel.html" class="btn btn-outline-secondary">
            Ethics panel &amp; oversight orientation
          </a>
          <a href="/universities/program-structures.html" class="btn btn-outline-secondary">
            Model program structures (conceptual)
          </a>
          <a href="/resources/faq.html" class="btn btn-outline-secondary">
            Read common questions
          </a>
          <a href="/legal/contact.html" class="btn btn-hero-primary text-white">
            Contact IIAIG about AI governance dialogue
          </a>
        </div>

        <p class="small text-muted mb-0">
          Any concrete AI governance implementation, assurance initiative or institutional collaboration should be
          handled through your organization’s formal legal, risk, compliance and governance processes, and documented
          in separate, clearly labeled instruments.
        </p>
      </div>
    </section>
  </main>

  <!-- Dynamic Footer -->
  <div id="footer-container"></div>

  <!-- Shared JS -->
  <script src="../main.js"></script>
</body>
</html>
