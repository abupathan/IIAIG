<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>ESG &amp; AI Governance – International Institute of AI Governance</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content="Conceptual overview of how environmental, social and governance (ESG) perspectives intersect with AI governance and responsible AI practice. Neutral orientation only – not an ESG rating, investment product, or regulatory framework."
  />

  <!-- Bootstrap 5 CSS -->
  <link
    href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
    rel="stylesheet"
  />

  <!-- Bootstrap Icons -->
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css"
  />

  <!-- Shared Theme -->
  <link rel="stylesheet" href="/styles.css" />
</head>
<body>

  <!-- Dynamic Navbar -->
  <div id="navbar-container"></div>

  <main>
    <!-- HERO: ESG & AI GOVERNANCE (CONCEPTUAL) -->
    <section class="hero-section hero-section--inner">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-lg-7">
            <div class="hero-kicker">
              <i class="bi bi-globe2" aria-hidden="true"></i>
              Standards · ESG &amp; AI Governance (Conceptual Orientation)
            </div>
            <h1 class="hero-title">
              Linking <span class="highlight">ESG perspectives</span> with AI governance
            </h1>
            <p class="hero-subtitle">
              This page offers a neutral, high-level orientation on how environmental, social and governance (ESG)
              perspectives intersect with AI governance and responsible AI practice. It is not an ESG rating,
              investment product, regulatory framework or legal advice, and does not assess or certify any organization.
            </p>
          </div>
          <div class="col-lg-5 mt-4 mt-lg-0">
            <div class="hero-panel">
              <div class="hero-panel-title">
                How to interpret this page
              </div>
              <ul class="list-unstyled mb-3 small text-secondary">
                <li class="mb-2 d-flex align-items-start gap-2">
                  <i class="bi bi-info-circle" aria-hidden="true"></i>
                  <span>
                    Provides a conceptual lens for integrating AI governance considerations into ESG thinking and
                    vice versa, from today through the 2030s.
                  </span>
                </li>
                <li class="mb-2 d-flex align-items-start gap-2">
                  <i class="bi bi-x-circle" aria-hidden="true"></i>
                  <span>
                    Does <strong>not</strong> offer investment recommendations, ESG ratings, scores or taxonomies
                    for specific entities, nor any label implying accreditation or endorsement.
                  </span>
                </li>
                <li class="mb-2 d-flex align-items-start gap-2">
                  <i class="bi bi-balance-scale" aria-hidden="true"></i>
                  <span>
                    Emphasizes that organizations remain responsible for interpreting applicable ESG- and AI-related
                    regulations with support from qualified advisors and internal governance processes.
                  </span>
                </li>
              </ul>
              <a href="#esg-view" class="btn btn-outline-light btn-sm me-2">
                ESG lens on AI
              </a>
              <a href="#mapping" class="btn btn-hero-primary btn-sm text-white">
                Mapping ESG to AI governance
              </a>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- SECTION: WHY ESG LENS MATTERS FOR AI -->
    <section id="esg-view" class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Overview</div>
            <h2 class="section-heading">Why ESG perspectives are increasingly relevant to AI governance</h2>
            <p class="section-subtitle">
              As organizations embed AI into core processes, questions that have traditionally sat within ESG discussions
              – climate impact, human rights, workforce implications, board oversight, disclosure and stakeholder trust –
              increasingly intersect with AI governance. Viewing AI through an ESG lens can support more integrated,
              long-term decision-making and more coherent narratives to stakeholders.
            </p>
          </div>
        </div>

        <div class="row g-4">
          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-tree" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Environmental implications</h5>
                <p class="card-text text-muted small mb-0">
                  AI-related activities can contribute to energy use, resource consumption and infrastructure
                  decisions. ESG perspectives encourage organizations to examine the environmental footprint of AI
                  and align it with broader sustainability goals and disclosures, where applicable – for example,
                  considering data center efficiency, model training strategies or demand management for high-intensity
                  workloads in a governance-aware way.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-people" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Social and human rights impacts</h5>
                <p class="card-text text-muted small mb-0">
                  AI systems can affect individuals and communities through decisions, recommendations or classifications.
                  ESG-oriented governance emphasizes effects on people: fairness, inclusion, non-discrimination, access,
                  working conditions and broader societal impacts of AI deployment, including how AI influences
                  work design, skills, and participation in economic and civic life.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-building" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Governance, oversight &amp; accountability</h5>
                <p class="card-text text-muted small mb-0">
                  ESG frameworks highlight the role of boards, senior management and control functions in overseeing
                  material risks. AI governance fits naturally into this governance dimension, shaping how AI-related
                  decisions are escalated, documented and communicated, and how AI risk is integrated into existing
                  risk, compliance and audit structures over time.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mt-4 mb-0">
          The relative emphasis on environmental, social or governance aspects for AI will differ by sector, use case
          and jurisdiction. This page provides general orientation only.
        </p>
      </div>
    </section>

    <!-- SECTION: ESG–AI MAPPING TABLE -->
    <section id="mapping" class="section-padding strip-section">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Mapping</div>
            <h2 class="section-heading">Conceptual mapping of ESG dimensions to AI governance topics</h2>
            <p class="section-subtitle">
              The table below outlines a neutral mapping between the three ESG dimensions and selected AI governance
              topics. It is illustrative and non-exhaustive, and does not refer to any particular ESG reporting
              framework, taxonomy or rating methodology.
            </p>
          </div>
        </div>

        <div class="table-responsive shadow-sm rounded-3">
          <table class="table table-bordered align-middle small mb-0">
            <thead class="table-light">
              <tr>
                <th scope="col">ESG dimension</th>
                <th scope="col">Conceptual AI governance focus</th>
                <th scope="col">Illustrative questions</th>
                <th scope="col">Potential evidence (examples)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th scope="row" class="fw-semibold">Environmental (E)</th>
                <td>
                  Understanding and managing environmental implications of AI infrastructure and tooling decisions.
                </td>
                <td>
                  How do AI workloads influence energy use and infrastructure choices? Are environmental factors
                  considered in AI-related procurement and architecture decisions? How are trade-offs between
                  performance, latency and environmental impact discussed and documented?
                </td>
                <td>
                  Concept notes on infrastructure strategy, internal guidance on efficient computing practices,
                  documentation of environmental considerations in relevant decisions, and references to sustainability
                  policies where AI is in scope.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">Social (S)</th>
                <td>
                  Assessing how AI affects individuals, communities, customers, employees and other stakeholders.
                </td>
                <td>
                  Could AI use lead to unfair outcomes, exclusion or disproportionate impacts? How are human rights,
                  dignity and accessibility considerations reflected in AI design and deployment? How are workforce
                  transitions and upskilling handled when AI changes roles or work patterns?
                </td>
                <td>
                  Impact assessments, records of stakeholder engagement, documentation on bias testing methods,
                  complaint and redress mechanisms in AI use cases, and training materials on responsible AI for
                  frontline teams.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">Governance (G)</th>
                <td>
                  Ensuring that AI-related decisions are subject to appropriate oversight, control and transparency.
                </td>
                <td>
                  Who is accountable for AI decisions? How are AI risks integrated into risk management, compliance
                  and audit processes? How are AI issues reported to governing bodies and how often are governance
                  arrangements reviewed?
                </td>
                <td>
                  Committee charters, AI governance policies, risk management frameworks, board reporting templates
                  that include AI topics, and documented escalation pathways for AI-related issues or incidents.
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <p class="small text-muted mt-4 mb-0">
          Organizations may extend or refine this mapping based on sectoral expectations, internal strategy and
          applicable laws or guidelines.
        </p>
      </div>
    </section>

    <!-- SECTION: INTEGRATING AI GOVERNANCE INTO ESG GOVERNANCE STRUCTURES -->
    <section class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Integration</div>
            <h2 class="section-heading">Conceptual ways to integrate AI governance into ESG governance structures</h2>
            <p class="section-subtitle">
              Many organizations already have governance structures for ESG topics – for example, board committees,
              risk committees, ethics councils or sustainability working groups. AI governance can be integrated into
              these structures in different ways, depending on context and maturity.
            </p>
          </div>
        </div>

        <div class="table-responsive shadow-sm rounded-3">
          <table class="table table-bordered align-middle small mb-0">
            <thead class="table-light">
              <tr>
                <th scope="col">Conceptual model</th>
                <th scope="col">High-level description</th>
                <th scope="col">Illustrative advantages</th>
                <th scope="col">Points to consider</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th scope="row" class="fw-semibold">A. AI within existing ESG/board committees</th>
                <td>
                  ESG or risk-related board committees explicitly add AI governance to their terms of reference and
                  receive periodic reporting on material AI topics.
                </td>
                <td>
                  Uses existing governance channels; highlights AI as part of broader sustainability and risk
                  agenda; may simplify escalation pathways and align AI with other strategic risks.
                </td>
                <td>
                  Requires clear scoping to avoid overloading committees; technical detail must be translated into
                  decision-useful information for board-level discussion; ownership of follow-up actions should be
                  well defined.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">
                  B. Dedicated AI or technology governance committee with ESG linkage
                </th>
                <td>
                  A specialized committee or council oversees AI and related technologies, with formal links to ESG,
                  risk and ethics structures.
                </td>
                <td>
                  Enables focused attention on AI-specific topics; can include a mix of technical, legal, risk and
                  ethics expertise; may be well-suited to organizations with significant AI footprint or complex
                  AI deployments.
                </td>
                <td>
                  Requires careful coordination with existing committees and clear definition of escalation routes
                  and responsibilities, to avoid duplicated oversight or gaps between bodies.
                </td>
              </tr>
              <tr>
                <th scope="row" class="fw-semibold">C. Distributed model with ESG-aligned minimum standards</th>
                <td>
                  AI governance responsibilities are embedded across multiple functions, underpinned by common
                  minimum standards aligned with ESG commitments.
                </td>
                <td>
                  Encourages shared ownership, integrates AI governance into everyday decision-making and can scale
                  across diverse business units or campuses.
                </td>
                <td>
                  Needs robust coordination, training and monitoring to avoid fragmentation; clarity of roles and
                  periodic effectiveness reviews are essential.
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <p class="small text-muted mt-4 mb-0">
          The right structure depends on an organization’s size, sector, regulatory environment and AI ambitions.
          This table provides orientation only.
        </p>
      </div>
    </section>

    <!-- SECTION: ESG, DISCLOSURE & STAKEHOLDER COMMUNICATION (CONCEPTUAL) -->
    <section class="section-padding strip-section">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Disclosure &amp; Stakeholders</div>
            <h2 class="section-heading">Conceptual view on AI within ESG disclosure &amp; stakeholder communication</h2>
            <p class="section-subtitle">
              Where organizations make ESG-related disclosures or engage with stakeholders on sustainability, it may be
              helpful to explain, at a high level, how AI governance fits into broader risk and responsibility
              narratives, taking into account applicable reporting rules and expectations.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-file-earmark-text" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Clear scope &amp; boundaries</h5>
                <p class="card-text text-muted small mb-0">
                  Disclosures related to AI should clarify what is in scope (for example, certain AI-enabled processes
                  or risk areas), avoid overstating coverage, and distinguish between forward-looking aspirations and
                  current capabilities – including uncertainties, limitations and areas still under development.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-people" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Stakeholder-centric narratives</h5>
                <p class="card-text text-muted small mb-0">
                  ESG narratives about AI may focus on how stakeholders are considered – for example, customer
                  fairness, employee upskilling, community impact and respect for rights – supported by governance
                  structures, documented processes and examples, rather than marketing claims alone.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-shield-lock" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Alignment with risk &amp; compliance</h5>
                <p class="card-text text-muted small mb-0">
                  Explanations of AI-related ESG topics are more credible when they align with internal risk
                  management, compliance and audit processes, rather than sitting entirely outside formal governance
                  structures or relying solely on voluntary initiatives.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          Organizations should ensure that any external communication about AI risks or ESG alignment is consistent
          with applicable disclosure rules and is reviewed through appropriate internal controls.
        </p>
      </div>
    </section>

    <!-- SECTION: FUTURE-READY ESG & AI VIEW -->
    <section class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Future-Ready View</div>
            <h2 class="section-heading">How ESG &amp; AI governance perspectives may evolve through the 2030s</h2>
            <p class="section-subtitle">
              While future developments will depend on policymakers, standard-setters and markets, organizations can
              anticipate certain broad themes in how ESG and AI governance may interact over the coming decade. The
              cards below present a neutral, speculative orientation – not predictions or commitments.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-bar-chart-line" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">More structured AI-related ESG indicators</h5>
                <p class="text-muted small mb-0">
                  Over time, organizations may be asked to provide more structured information on how AI affects key
                  ESG themes – for example, selected metrics, narrative indicators or case-based evidence – while
                  recognizing the limits of comparability and the need to avoid oversimplified scoring of complex
                  AI-related impacts.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-diagram-3" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Closer links between AI governance and climate &amp; just transition debates</h5>
                <p class="text-muted small mb-0">
                  Discussions about climate transition and “just transition” for workers may increasingly consider
                  the role of AI – including how AI-intensive infrastructure is managed and how AI is used to support
                  or hinder fair, inclusive transitions in industries, education and public services.
                </p>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card why-card h-100">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-people-fill" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">Broader stakeholder expectations on AI transparency</h5>
                <p class="text-muted small mb-0">
                  Stakeholders – including students, employees, customers, communities and investors – may increasingly
                  expect organizations to explain, in understandable terms, how AI affects them and what governance
                  safeguards exist, particularly in high-impact use cases and public-interest settings.
                </p>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          These themes are indicative only. Organizations should monitor developments in their sectors and jurisdictions
          and update ESG and AI governance approaches through formal governance processes.
        </p>
      </div>
    </section>

    <!-- SECTION: ILLUSTRATIVE (FICTIONAL) SCENARIOS -->
    <section class="section-padding strip-section">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Illustrative Scenarios</div>
            <h2 class="section-heading">Example (fictional) ESG–AI governance scenarios</h2>
            <p class="section-subtitle">
              The scenarios below are fictional and intended only to illustrate how ESG and AI governance perspectives
              might intersect in different institutional contexts. They are not descriptions of any real organization or
              regulatory expectation.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-4">
            <div class="card pathway-card h-100">
              <div class="card-body">
                <div class="pathway-pill">
                  <i class="bi bi-bank" aria-hidden="true"></i>
                  Scenario A – University ESG committee
                </div>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    A university ESG committee adds AI use in teaching and administration to its agenda.
                  </li>
                  <li class="mb-1">
                    It requests a short AI governance overview, including student impact and academic integrity
                    considerations, and how AI relates to existing equity and inclusion commitments.
                  </li>
                  <li class="mb-1">
                    The committee agrees on high-level principles and escalates technical implementation details to a
                    specialized working group, with regular feedback loops.
                  </li>
                </ul>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card pathway-card h-100">
              <div class="card-body">
                <div class="pathway-pill">
                  <i class="bi bi-briefcase" aria-hidden="true"></i>
                  Scenario B – Corporate sustainability report
                </div>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    A company prepares a sustainability report and includes a section describing its governance
                    approach to AI-related risks and opportunities.
                  </li>
                  <li class="mb-1">
                    The description references internal policies, roles and processes, avoiding claims about specific
                    outcomes that cannot be substantiated and clearly differentiating between current practice and
                    planned improvements.
                  </li>
                  <li class="mb-1">
                    The text is reviewed by legal and risk teams to ensure consistency with other disclosures and
                    regulatory filings.
                  </li>
                </ul>
              </div>
            </div>
          </div>

          <div class="col-md-4">
            <div class="card pathway-card h-100">
              <div class="card-body">
                <div class="pathway-pill">
                  <i class="bi bi-people" aria-hidden="true"></i>
                  Scenario C – Investor–issuer dialogue
                </div>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    Investors ask a company how it manages social and governance risks linked to AI-based products.
                  </li>
                  <li class="mb-1">
                    The company provides a high-level overview of its AI governance model, escalation routes and
                    oversight structures, without revealing proprietary details.
                  </li>
                  <li class="mb-1">
                    The conversation informs both sides’ understanding of AI within broader ESG risk discussions and
                    may shape future engagement priorities.
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          Actual practices should always reflect organization-specific circumstances, regulatory guidance and advice
          from qualified professionals.
        </p>
      </div>
    </section>

    <!-- SECTION: CLARITY – WHAT THIS PAGE DOES / DOES NOT DO -->
    <section class="section-padding">
      <div class="container">
        <div class="row mb-4">
          <div class="col-lg-9">
            <div class="section-kicker">Clarity</div>
            <h2 class="section-heading">What this ESG &amp; AI Governance page does – and does not – represent</h2>
            <p class="section-subtitle">
              To keep expectations clear, it is important to distinguish this conceptual orientation from investment,
              regulatory or assurance activities.
            </p>
          </div>
        </div>

        <div class="row g-4 mb-4">
          <div class="col-md-6">
            <div class="card why-card h-100 border-success-subtle">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-check2-circle" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">What this page does</h5>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    Provides a neutral vocabulary for discussing how ESG perspectives intersect with AI governance.
                  </li>
                  <li class="mb-1">
                    Highlights conceptual options for integrating AI governance topics into ESG governance and
                    stakeholder dialogue.
                  </li>
                  <li class="mb-1">
                    Encourages organizations and institutions to treat AI as part of broader sustainability and
                    governance conversations, where relevant.
                  </li>
                </ul>
              </div>
            </div>
          </div>

          <div class="col-md-6">
            <div class="card why-card h-100 border-danger-subtle">
              <div class="card-body">
                <div class="icon-circle">
                  <i class="bi bi-x-octagon" aria-hidden="true"></i>
                </div>
                <h5 class="card-title">What this page does not do</h5>
                <ul class="small text-muted ps-3 mb-0">
                  <li class="mb-1">
                    Does <strong>not</strong> provide ESG ratings, scores, labels, taxonomies or investment
                    recommendations.
                  </li>
                  <li class="mb-1">
                    Does <strong>not</strong> replace any applicable law, regulation, reporting standard or
                    supervisory guidance.
                  </li>
                  <li class="mb-1">
                    Does <strong>not</strong> constitute legal, investment or risk advice, nor create any supervisory
                    or contractual obligations.
                  </li>
                  <li class="mb-1">
                    Does <strong>not</strong> claim accreditation, regulatory authority or endorsement for IIAIG, or
                    imply that IIAIG provides ESG assurance services.
                  </li>
                </ul>
              </div>
            </div>
          </div>
        </div>

        <p class="small text-muted mb-0">
          Users of this page should consult relevant legal, regulatory and reporting requirements in their jurisdiction,
          and seek professional advice where necessary.
        </p>
      </div>
    </section>

    <!-- SECTION: NEXT STEPS -->
    <section class="section-padding strip-section">
      <div class="container text-center">
        <div class="row justify-content-center mb-4">
          <div class="col-lg-8">
            <div class="section-kicker">Next Steps</div>
            <h2 class="section-heading">Using this orientation in your ESG &amp; AI governance work</h2>
            <p class="section-subtitle">
              Boards, executives, risk and sustainability teams, universities and practitioners can use this page as a
              starting point to reflect on how AI governance features in their ESG strategies, governance structures and
              stakeholder communication – always anchored in applicable rules and institutional context.
            </p>
          </div>
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-center gap-3 mb-3">
          <a href="/standards/" class="btn btn-outline-secondary">
            AI governance &amp; risk frameworks
          </a>
          <a href="/standards/ethics-panel.html" class="btn btn-outline-secondary">
            Ethics panel &amp; oversight
          </a>
          <a href="/resources/faq.html" class="btn btn-outline-secondary">
            Read common questions
          </a>
          <a href="/legal/contact.html" class="btn btn-hero-primary text-white">
            Contact IIAIG about ESG–AI dialogue
          </a>
        </div>

        <p class="small text-muted mb-0">
          Any concrete ESG reporting, assurance or investment decision remains the responsibility of the relevant
          institution and its advisors. This page is for conceptual orientation only.
        </p>
      </div>
    </section>
  </main>

  <!-- Dynamic Footer -->
  <div id="footer-container"></div>

  <!-- Shared JS -->
  <script src="/main.js"></script>
</body>
</html>
